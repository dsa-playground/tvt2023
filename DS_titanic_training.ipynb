{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dsa-playground/tvt2023.git\n",
    "%cd /content/tvt2023/\n",
    "!git pull\n",
    "!pip install -r requirements.txt -t \"tvt2023\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inleiding\n",
    "\n",
    "### Use case 'Titanic'\n",
    "Ruim honderd jaar geleden (1912) zonk de Titanic, vier uur nadat het schip op een ijsberg was gelopen. Slechts een derde deel van de opvarende overleefde deze ramp. Veel van deze gebeurtenis is vastgelegd, waaronder ook een dataset van passagiers. Deze dataset leent zich goed voor een introductie in de Data Science. Kan een algoritme voorspellen of een passagier overleeft? En, als je jezelf toevoegd, zou jij het dan overleefd hebben?\n",
    "\n",
    "<!-- ![Laatste foto van de Titanic](../tvt2023/images/lastphoto_titanic.png) -->\n",
    "<img src=../tvt2023/images/lastphoto_titanic.png alt=\"Laatste foto van de Titanic\">\n",
    "\n",
    "### Instructies omgeving\n",
    "Voor deze workshop werken we in Google Colab. Dit is een online ontwikkelomgeving waarin je eenvoudig kunt experimenteren. Het notebook wat we voorbereid hebben staat al klaar. In een notebook staan cellen met ofwel code, tekst of afbeeldingen. Om een cel af te trappen (code draaien) zijn er twee mogelijkheden:\n",
    "- Play-knop links van de cel\n",
    "- Ctrl + Enter\n",
    "\n",
    "### Imports & settings\n",
    "Data Science heeft een sterke component met Computer Science. De meeste programmatuur zit op de achtergrond, maar om gebruik te maken van de functionaliteiten worden de functies en instellingen geladen in de cel hieronder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from scripts.preprocess.preprocess_frontend import zie_settings, laden_data, opschonen_data, numeriek_maken_data, voeg_passagiers_toe\n",
    "from scripts.EDA.eda import basis_feiten, EDA_visualisaties, correlatie_heatmap\n",
    "from scripts.modeling.modeling_frontend import train_and_save_model, voorspelling_genereren\n",
    "\n",
    "# Settings\n",
    "# settings for pandas\n",
    "pd.set_option(\"display.max.columns\",None) # alle kolommen tonen\n",
    "pd.set_option(\"display.max.rows\",500)    # eerste 500 rijen tonen\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = zie_settings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science is geen doel op zich. Het doel is antwoord vinden voor een vraagstuk. Om te borgen dat Data (Science) producten aansluiten bij de wensen van een klant kan men het CRISP-DM proces (Cross-Industry Standard Process for Data Mining) volgen. \n",
    "\n",
    "\n",
    "<img src=../tvt2023/images/CRISP-DM.png width=400 height=400 alt=\"CRISP-DM\">\n",
    "\n",
    "Dit proces doorloopt de volgende stappen:\n",
    "- Business understanding: Vinden van de hypothese en context.\n",
    "- Data understanding: Verzamelen van relevante data.\n",
    "- Data preparation: Aanpassen data zodat deze bruikbaar is voor algoritme.\n",
    "- Modeling: Opzetten/inrichten algoritme om antwoord te vinden op hypothese. \n",
    "- Evaluation: Reflecteren of resultaat model hypothese verwerpt of aanneemt.\n",
    "- Deployment: Naar productieomgeving brengen (zorg dragen dat model meermaals gebruikt kan worden). \n",
    "\n",
    "### Business Understanding\n",
    "Het vraagstuk nu concentreert zich op wel/niet overleven van de Titanic. Oftewel:\n",
    "- *Kan een algoritme voorspellen of een passagier de Titanic overleefd?*\n",
    "\n",
    "En... door onszelf toe te voegen kijken of **wij** dit hadden overleefd!\n",
    "\n",
    "### Data Understanding\n",
    "Er is een dataset beschikbaar met informatie van passagiers. Er zijn twee datasets:\n",
    "1. train: Dataset met passagiers Ã©n informatie of zij wel/niet overleefd hebben\n",
    "2. test: Dataset met passagiers *zonder* informatie of zij wel/niet overleefd hebben\n",
    "Laten we eens kijken naar de train dataset. Draai de code door op de playknop te drukken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = laden_data()\n",
    "display(df_train.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet is de dataset in het Engels en soms wat cryptisch weergegeven. Om het iets eenvoudiger te maken, transformeren we de dataset naar iets begrijpelijkere taal en zetten we vergelijkbare informatie bij elkaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean, df_test_clean = opschonen_data(df_train, df_test)\n",
    "display(df_train_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data die we nu zien heeft informatie over:\n",
    "* Passagier: ID, naam, geslacht, leeftijd, opstapplaats, aantal kinderen, aantal overige familieleden, totaal aantal familieleden\n",
    "* Reisinformatie: Opstapplaats, ticket nummer, ticket klasse, cabine nummer\n",
    "* Overleefd ja/nee\n",
    "\n",
    "Wat we willen voorspellen is of mensen het overleefd hebben. De kolom 'Overleefd' is wat we noemen 'target-variabele'. De andere variabelen zijn mogelijk de verklarende variabelen. Om te kijken of er waarde zit in de variabelen, doen we een verkennende gegevensanalyse (EDA: exploratory data analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_feiten(df=df_train_clean)\n",
    "EDA_visualisaties(df=df_train_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Gezien de dataset en deze visualisaties, kunnen we de dataset nog iets meer aanpassen zodat we dit kunnen toepassen met een model. Aanpassingen welke benodigd zijn:\n",
    "- Verwijderen kolommen met geen relevante data (zoals 'ticket_nummer')\n",
    "- Verwijderen kolommen met veel missende data (zoals 'cabine_nummer')\n",
    "- Vullen van missende waarden waar mogelijk (zoals bij 'leeftijd')\n",
    "- Afronden van leeftijd (34,5 jaar = 34 jaar)\n",
    "- Numeriek maken van waarden (geslacht, opstapplaats, ticket_klasse, overleefd)\n",
    "- Nieuwe index maken (unieke combinatie per rij)\n",
    "\n",
    "Dit leidt tot de volgende datasets (train & test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num, df_test_num = numeriek_maken_data(df_train_clean, df_test_clean)\n",
    "display(df_train_num.head(), df_test_num.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dataset is bijna klaar voor het toepassen van een model, maar... we willen natuurlijk ook weten of je het zelf overleefd zou hebben! Laten we onszelf toevoegen aan de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_extended, df_test_extended = voeg_passagiers_toe(df_train_num, df_test_num)\n",
    "display(df_train_extended.tail(), df_test_extended.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Zoals in de presentatie besproken zijn er verschillende algoritmes om vraagstukken op te lossen. In deze workshop gaan we voor een classificatie-algoritme: KNN (K Nearest Neighbor). Hoe dit algoritme werkt laat zich het beste uitleggen op basis van een animatie:\n",
    "\n",
    "<img src=../tvt2023/images/knn.gif alt=\"KNN\">\n",
    "\n",
    "bron: https://github.com/TomasBeuzen/machine-learning-tutorials/blob/master/ml-animations/gif/knn/knn.gif\n",
    "\n",
    "Wat het algoritme doet is het bepaald tot welke groep een 'onbekend' punt behoort, door de dichtsbijzijnde punten te zoeken. De meerderheid van wat die punten zijn, bepalen wat het 'onbekende' punt wordt. Een variabele waar je in het trainen van een model mee experimenteert is bijvoorbeeld het aantal buren. \n",
    "\n",
    "Natuurlijk is dit een vereenvoudigd voorbeeld met slechts 2 variabelen (X1 en X2). In het geval van de Titanic dataset zijn er veel meer variabelen en dus dimensies. Wij als mensen kunnen tot 3 dimensies vrij aardig visualiseren. Een algoritme is natuurlijk niet geremd door meer dimensies. \n",
    "\n",
    "Laten we een model trainen met een aantal verschillende buren (van 1 tot 20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_save_model(df=df_train_extended)\n",
    "\n",
    "# Aanpassen functie zodat resultaten zichtbaar worden in DataFrame\n",
    "# Willen we nog iets met classification report: ja\n",
    "# Stukje uitleg over evaluatie --> daarna brug naar kiezen buren en voorspellen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kun je kiezen wat voor jou de meest logische keuze is voor het aantal buren.\n",
    "Belangrijk: Weet dat het aantal buren:\n",
    "* Geen waarde gelijk aan het aantal klassen dat het moet voorspellen.\n",
    "* Geen veelvoud van het aantal klassen dat het moet voorspellen.\n",
    "\n",
    "In het voorbeeld van de Titanic zijn er 2 klassen (overleefd/niet overleefd). Dus kies geen even getal.\n",
    "\n",
    "Ps. Natuurlijk kun je dit automatiseren, voor de workshop hebben we dit niet gedaan voor het spelelement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kies aantal buren en train een model daarop + voorspellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voorspelling = voorspelling_genereren(X=df_test_extended)\n",
    "display(df_voorspelling.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zorg dragen voor leuk einde, bijv. leuke visualisatie (gehele populatie met 2 bestuurders highlight) \n",
    "# of 'je hebt de Titanic dan misschien niet overleefd, maar wel deze workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "# - Zorgen dat bepaalde warnings e.d. niet zichtbaar zijn. \n",
    "# - Zorgen dat we weten wat bijdraagt aan de kans van overleven. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_extended.tail()\n",
    "# df_train_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testlist = df_train_num.columns\n",
    "# m1 = ['Overleefd']\n",
    "# not_in_testlist = list(set(testlist) - set(m1))\n",
    "# not_in_testlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X=df_train_num[['Geslacht', 'Leeftijd', 'Opstapplaats', 'Aantal_kinderen',\n",
    "#        'Aantal_overige_familieleden', 'Ticket_klasse', 'Ticket_prijs']]\n",
    "# y=df_train_num['Overleefd']\n",
    "# # X_test = df_test_num[['Geslacht', 'Leeftijd', 'Opstapplaats', 'Aantal_kinderen',\n",
    "# #        'Aantal_overige_familieleden', 'Ticket_klasse', 'Ticket_prijs']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#     test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# acc = []\n",
    "\n",
    "# for i in range(1,20):\n",
    "#     knn = KNeighborsClassifier(n_neighbors = i)\n",
    "#     knn.fit(X_train,y_train)\n",
    "#     yhat = knn.predict(X_test)\n",
    "#     acc.append(accuracy_score(y_test,yhat))\n",
    "#     print(\"For k = \",i,\" : \",accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(range(1,20),acc, marker = \"o\")\n",
    "# plt.xlabel(\"Value of k\")\n",
    "# plt.ylabel(\"Accuracy Score\")\n",
    "# plt.title(\"Finding the right k\")\n",
    "# plt.xticks(range(1,20))\n",
    "# plt.show()\n",
    "# max(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc.index(max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# df = df = pd.DataFrame(dict(\n",
    "#     Num_neighbours = range(1,20),\n",
    "#     accuracy_score = acc\n",
    "# ))\n",
    "# fig = px.line(df, x=\"Num_neighbours\", y=\"accuracy_score\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN = KNeighborsClassifier(n_neighbors = 3)\n",
    "# KNN.fit(X,y)\n",
    "# y_pred = KNN.predict(X_test)\n",
    "# df_KNN = pd.DataFrame()\n",
    "# # df_KNN[\"PassengerId\"] = test2[\"PassengerId\"]\n",
    "# # df_KNN[\"Survived\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['Overleefd']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
