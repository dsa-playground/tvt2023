{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/dsa-playground/tvt2023.git\n",
    "# %cd /content/tvt2023/\n",
    "# !git pull\n",
    "# !pip install -r requirements.txt -t \"tvt2023\"\n",
    "# !pip install pyaml-env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inleiding\n",
    "\n",
    "### Use case 'Titanic'\n",
    "Ruim honderd jaar geleden (1912) zonk de Titanic, vier uur nadat het schip op een ijsberg was gelopen. Slechts een derde deel van de opvarende overleefde deze ramp. Veel van deze gebeurtenis is vastgelegd, waaronder ook een dataset van passagiers. Deze dataset leent zich goed voor een introductie in de Data Science. Kan een algoritme voorspellen of een passagier overleeft? En, als je jezelf toevoegd, zou jij het dan overleefd hebben?\n",
    "\n",
    "![Laatste foto van de Titanic](https://raw.githubusercontent.com/dsa-playground/tvt2023/main/images/lastphoto_titanic.png)\n",
    "\n",
    "### Instructies omgeving\n",
    "Voor deze workshop werken we in Google Colab. Dit is een online ontwikkelomgeving waarin je eenvoudig kunt experimenteren. Het notebook wat we voorbereid hebben staat al klaar. In een notebook staan cellen met ofwel code, tekst of afbeeldingen. Om de code in een cel te draaien zijn er twee mogelijkheden:\n",
    "- Play-knop links van de cel\n",
    "- Ctrl + Enter\n",
    "\n",
    "### 0. Klaarzetten software\n",
    "Data Science heeft een sterke component met Computer Science. De meeste programmatuur zit op de achtergrond, maar om gebruik te maken van de functionaliteiten worden de functies en instellingen geladen in de cel hieronder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scripts.preprocess.preprocess_frontend import laden_data, opschonen_data, numeriek_maken_data, voeg_passagiers_toe\n",
    "from scripts.EDA.eda import basis_feiten, visualisatie_ticketklasse, visualisatie_opstapplaats, visualisatie_leeftijd ,visualisatie_leeftijd_geslacht ,visualisatie_familieleden\n",
    "from scripts.modeling.modeling_frontend import experimenteer_met_aantal_buren, verdieping_specifiek_model, voorspelling_genereren\n",
    "from scripts.evaluation.evaluation import geef_belangrijkste_variabelen \n",
    "\n",
    "# Settings\n",
    "# settings for pandas\n",
    "pd.set_option(\"display.max.columns\",None) # alle kolommen tonen\n",
    "pd.set_option(\"display.max.rows\",500)    # eerste 500 rijen tonen\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Science Proces\n",
    "Data Science is geen doel op zich. Het doel is antwoord vinden voor een vraagstuk. Om te borgen dat Data (Science) producten aansluiten bij de wensen van een klant kan men het CRISP-DM proces (Cross-Industry Standard Process for Data Mining) volgen. \n",
    "\n",
    "<img src=https://raw.githubusercontent.com/dsa-playground/tvt2023/main/images/CRISP-DM.png width=400 height=400 alt=\"CRISP-DM\">\n",
    "\n",
    "Dit proces doorloopt de volgende stappen:\n",
    "- Business understanding: Vinden van de hypothese en context.\n",
    "- Data understanding: Verzamelen van relevante data.\n",
    "- Data preparation: Aanpassen data zodat deze bruikbaar is voor algoritme.\n",
    "- Modeling: Opzetten/inrichten algoritme om antwoord te vinden op hypothese. \n",
    "- Evaluation: Reflecteren of resultaat model hypothese verwerpt of aanneemt.\n",
    "- Deployment: Naar productieomgeving brengen (zorg dragen dat model meermaals gebruikt kan worden). \n",
    "\n",
    "### 2. Business Understanding\n",
    "Het vraagstuk nu concentreert zich op wel/niet overleven van de Titanic. Oftewel:\n",
    "- *Kan een algoritme voorspellen of een passagier de Titanic overleefd?*\n",
    "\n",
    "En... door onszelf toe te voegen kijken of **wij** dit hadden overleefd!\n",
    "\n",
    "### 3. Data Understanding\n",
    "Er is een dataset beschikbaar met informatie van passagiers. Deze is gesplitst in twee datasets:\n",
    "\n",
    "1. Train: Dataset met passagiers én informatie of zij wel/niet overleefd hebben\n",
    "2. Test: Dataset met passagiers *zonder* informatie of zij wel/niet overleefd hebben\n",
    "\n",
    "Laten we eens kijken naar de train dataset. Draai de code door op de playknop te drukken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = laden_data()\n",
    "display(df_train.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet is de dataset in het Engels en soms wat cryptisch weergegeven.   \n",
    "Om het iets eenvoudiger te maken, transformeren we de dataset naar iets begrijpelijkere taal en zetten we vergelijkbare informatie bij elkaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean, df_test_clean = opschonen_data(df_train, df_test)\n",
    "display(df_train_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data die we nu zien heeft informatie over:\n",
    "* Passagier: ID, naam, geslacht, leeftijd, opstapplaats, aantal kinderen, aantal overige familieleden, totaal aantal familieleden\n",
    "* Reisinformatie: Opstapplaats, ticket nummer, ticket klasse, cabine nummer\n",
    "* Overleefd ja/nee\n",
    "\n",
    "Wat we willen voorspellen is of mensen het overleefd hebben. De kolom 'Overleefd' is wat we noemen 'target-variabele'. De andere variabelen zijn mogelijk de verklarende variabelen. Om te kijken of er waarde zit in de variabelen, doen we een verkennende gegevensanalyse (EDA: exploratory data analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_feiten(df=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisatie_ticketklasse(df=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisatie_opstapplaats(df=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisatie_leeftijd(df=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisatie_leeftijd_geslacht(df=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisatie_familieleden(df=df_train_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data preparation\n",
    "Uit de verkennende gegevensanalyse blijkt dat we de dataset moeten aanpassen voordat we deze kunnen gebruiken in een voorspelling. De volgende aanpassingen zijn nodig:\n",
    "- Verwijderen kolommen met geen relevante data (zoals 'ticket_nummer')\n",
    "- Verwijderen kolommen met veel missende data (zoals 'cabine_nummer')\n",
    "- Vullen van missende waarden waar mogelijk (zoals bij 'leeftijd')\n",
    "- Afronden van leeftijd (34,5 jaar = 34 jaar)\n",
    "- Numeriek maken van waarden (geslacht, opstapplaats, ticket_klasse, overleefd)\n",
    "- Nieuwe index maken (unieke combinatie per rij)\n",
    "\n",
    "Dit leidt tot de volgende datasets (train & test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num, df_test_num = numeriek_maken_data(df_train_clean, df_test_clean)\n",
    "display(df_train_num.head(), df_test_num.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dataset is bijna klaar voor het toepassen van een model, maar... we willen natuurlijk ook weten of je het zelf overleefd zou hebben! Laten we onszelf toevoegen aan de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_extended, df_test_extended = voeg_passagiers_toe(df_train_num, df_test_num)\n",
    "display(df_test_extended.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modeling\n",
    "Zoals in de presentatie besproken zijn er verschillende algoritmes om vraagstukken op te lossen.  \n",
    " In deze workshop gaan we voor een classificatie-algoritme: KNN (K Nearest Neighbor). \n",
    " \n",
    " Hoe dit algoritme werkt laat zich het beste uitleggen op basis van een animatie:\n",
    "\n",
    "![knn](https://raw.githubusercontent.com/dsa-playground/tvt2023/main/images/knn.gif)\n",
    "\n",
    "Wat het algoritme doet is het bepaald tot welke groep een 'onbekend' punt behoort, door de dichtsbijzijnde punten te zoeken.  \n",
    "De meerderheid van de dichtstbijzijnde punten, bepalen wat het 'onbekende' punt wordt. \n",
    "\n",
    "Een variabele waar je in het trainen van een model mee experimenteert is bijvoorbeeld het aantal buren.  \n",
    "Deze 'buren' zijn het aantal dichtstbijzijnde punten waarmee rekening wordt gehouden.\n",
    "\n",
    "Natuurlijk is dit een vereenvoudigd voorbeeld met slechts 2 variabelen (X1 en X2).  \n",
    "In het geval van de Titanic dataset zijn er veel meer variabelen en dus dimensies. \n",
    "\n",
    "Wij als mensen kunnen tot 3 dimensies vrij aardig visualiseren, daarna is eigenlijk al niet meer te doen.  \n",
    "Gelukkig wordt een algoritme niet geremd door meer dimensies. \n",
    "\n",
    "Om ons eigen model te trainen, moeten we ook ingeven met hoeveel buren er rekening gehouden moet worden.\n",
    "We weten echter niet bij hoeveel buren het beste model gevonden wordt. \n",
    "\n",
    "Gelukkig is dit allemaal uit te rekenen, dus laten we experimenteren met een aantal verschillende buren (van 1 tot 15):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment = experimenteer_met_aantal_buren(df=df_train_extended, ondergrens=1, bovengrens=15)\n",
    "display(df_experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluation\n",
    "\n",
    "Maar hoe weet je nu wanneer een voorspelling 'goed genoeg' is?  \n",
    "En hoe vergelijk je verschillende voorspellingen met elkaar?\n",
    "\n",
    "Voor de evaluatie van voorspellingen zijn gelukkig verschillende metrieken ontwikkeld.  \n",
    "In deze casus is gekozen voor de metriek genaamd 'nauwkeurigheidsscore', deze geeft aan hoeveel procent juist voorspeld is. \n",
    "\n",
    "De basis voor deze nauwkeurigheidsscore is in de cel hieronder gevisualiseerd, door middel van een zogenaamde 'verwarringsmatrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_matrix = verdieping_specifiek_model(df=df_train_extended, aantal_buren=3)\n",
    "display(df_confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In bovenstaande verwarringsmatrix worden twee assen met elkaar gecombineerd:\n",
    "\n",
    "* Wel/niet overleefd\n",
    "* Werkelijke waarde vs voorspelde waarde\n",
    "\n",
    "Wanneer je deze assen tegen elkaar afzet levert dat vier verschillende categorieën op:\n",
    "\n",
    "* 87 passagiers die zijn overleden en waarbij de voorspelling ook overleden is (juiste voorspelling, 'True Negatives')\n",
    "* 18 passagiers die zijn overleden maar waarbij de voorspelling overleefd is (onjuiste voorspelling, 'False Positives')\n",
    "* 28 passagiers die het hebben overleefd maar waarbij de voorspelling overleden is (onjuiste voorspelling, 'False Negatives')\n",
    "* 45 passagiers die het hebben overleefd en waarbij de voorspelling ook overleefd is (juiste voorspelling, 'True Positives')\n",
    "\n",
    "De nauwkeurigheidsscore wordt berekend door de aantallen van de juiste voorspellingen te delen door het totaal. In het voorbeeld van 3 buren:\n",
    "\n",
    "${(87+45) \\over (87+18+28+45)} = {132 \\over 178} = 0.742$\n",
    "\n",
    "Het is in de evaluatiefase belangrijk om goed na te denken over de metriek die je kiest. De nauwkeurigsheiddscore houd bijvoorbeeld rekening met zowel de 'True Negatives' als de 'True Positives'. Maar er zijn, zeker in de zorg, genoeg voorbeelden te vinden waarbij je juist de nadruk wilt leggen op maar één van die twee. En dat heeft vervolgens ook weer invloed op welk algoritme het beste het uit de bus komt.\n",
    "\n",
    "Nu terug naar onze use case. Laten we de passagiers voorspellen waarvoor het onbekend is, waaronder ons zelf! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voorspelling = voorspelling_genereren(X=df_test_extended)\n",
    "display(df_voorspelling.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor sommige is het resultaat wellicht teleurstellend.   \n",
    "Maar wees gerust, er zijn een aantal variabelen doorslaggevend en bij een goed doorlopen CRISP-DM proces heb je deze in beeld en kun (vroegtijdig) ingrijpen.  \n",
    "\n",
    "In onderstaande visualisatie kun je zien welke variabelen doorgeslaggevend waren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geef_belangrijkste_variabelen(df_train_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deployment\n",
    "\n",
    "Het CRISP-DM proces is een iteratief proces. \n",
    "\n",
    "In elke stap kan een inzicht zijn wat leidt tot nieuwe afstemming of herzien van instellingen.  \n",
    " Met als doel dat het resultaat voldoet aan de eisen/verwachtingen bij de klant. \n",
    "\n",
    "Wanneer alles naar wens is dan kan men overgaan tot de laatste fase: 'Deployment'.   \n",
    "Deze fase is niet te onderschatten, want hierin komen weer hele andere vaardigheden kijken dan puur het maken van voorspelling. \n",
    "\n",
    "Een gemaakte voorspelling moet bijvoorbeeld regelmatig opnieuw geëvalueerd worden op basis van nieuwe data.   \n",
    "Gelukkig hoeven we daar met de Titanic niet mee aan de slag, want dit was puur een introductie tot ons mooie vakgebied!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
